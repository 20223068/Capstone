import os
import json
import pymysql
import numpy as np
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
from sentence_transformers import SentenceTransformer
from openai import OpenAI

from gtts import gTTS
from flask import send_file
import io
from io import BytesIO

from collections import defaultdict, Counter
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

from sklearn.cluster import DBSCAN
import random

app = Flask(__name__, template_folder="templates")
CORS(app)

# DB ì—°ê²°
connection = pymysql.connect(
    host='127.0.0.1',
    port=3306,
    user='root',
    password='1234',
    db='fairy_db',
    charset='utf8mb4',
    cursorclass=pymysql.cursors.DictCursor
)
cursor = connection.cursor()

# ì„ë² ë”© ëª¨ë¸ ë¡œë”©
model = SentenceTransformer("all-MiniLM-L6-v2")

# LM Studio í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
client = OpenAI(
    base_url="http://127.0.0.1:1234/v1",
    api_key="lm-studio"  # ì•„ë¬´ ë¬¸ìì—´
)

# ì½”ì‚¬ì¸ ìœ ì‚¬ë„
def cosine_similarity(vec1, vec2):
    v1, v2 = np.array(vec1), np.array(vec2)
    return float(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))

# ì§ˆë¬¸ ì €ì¥
def save_question(text, slide_index):
    try:
        page_num = slide_index + 1  # âœ… HTMLìƒ í˜ì´ì§€ ë²ˆí˜¸ì™€ ë§ì¶”ê¸° ìœ„í•œ ë³´ì •
        cursor.execute("INSERT INTO questions (questions, page_num) VALUES (%s, %s)", (text, page_num))
        connection.commit()
        return cursor.lastrowid
    except Exception as e:
        print("âŒ ì§ˆë¬¸ ì €ì¥ ì˜¤ë¥˜:", e)
        return None

# ì§ˆë¬¸ ì„ë² ë”© ì €ì¥
def save_question_embedding(qid, embedding):
    try:
        cursor.execute("INSERT INTO question_embeddings (question_id, embedding) VALUES (%s, %s)", (qid, json.dumps(embedding)))
        connection.commit()
    except Exception as e:
        print("âŒ ì§ˆë¬¸ ì„ë² ë”© ì €ì¥ ì˜¤ë¥˜:", e)

# ë‹µë³€ ì €ì¥
def save_answer(qid, answer):
    try:
        cursor.execute("INSERT INTO answers (question_id, answers) VALUES (%s, %s)", (qid, answer))
        connection.commit()
    except Exception as e:
        print("âŒ ë‹µë³€ ì €ì¥ ì˜¤ë¥˜:", e)

# ìœ ì‚¬ ì§ˆë¬¸ ì°¾ê¸°
def find_similar_question(embedding):
    cursor.execute("SELECT question_id, embedding FROM question_embeddings")
    best_score, best_id = 0, None
    for row in cursor.fetchall():
        e = json.loads(row['embedding'])
        score = cosine_similarity(embedding, e)
        if score > best_score:
            best_score, best_id = score, row['question_id']
    return best_id if best_score > 0.9 else None

# í•´ë‹¹ ì§ˆë¬¸ì˜ ë‹µë³€ ê°€ì ¸ì˜¤ê¸°
def get_answer_by_question_id(qid):
    cursor.execute("SELECT answers FROM answers WHERE question_id = %s", (qid,))
    row = cursor.fetchone()
    return row["answers"] if row else None

# story_chunksì—ì„œ ìœ ì‚¬ ë¬¸ë‹¨ ì°¾ê¸°
def find_relevant_story_chunks(embedding, top_n=3):
    cursor.execute("SELECT id, chunk_text, embedding FROM story_chunks WHERE embedding IS NOT NULL")
    chunks = cursor.fetchall()
    scored = []
    for row in chunks:
        chunk_emb = json.loads(row["embedding"])
        score = cosine_similarity(embedding, chunk_emb)
        scored.append((score, row["chunk_text"]))
    scored.sort(reverse=True, key=lambda x: x[0])
    return [chunk for _, chunk in scored[:top_n]]

# GPTì—ê²Œ ë‹µë³€ ìš”ì²­
def get_gpt_answer_with_context(question, context_chunks):
    story_context = "\n".join(context_chunks)
    messages = [
        {"role": "system", "content": f"ì´ê±´ ì–´ë¦°ì´ ë™í™”ì— ëŒ€í•œ ì§ˆë¬¸ì´ì•¼. ì•„ë˜ ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ì•„ì´ê°€ ì´í•´í•˜ê¸° ì‰½ê³  ë”°ëœ»í•˜ê²Œ ëŒ€ë‹µí•´ì¤˜:\n\n{story_context}"},
        {"role": "user", "content": question}
    ]
    try:
        response = client.chat.completions.create(
            model="openhermes-2.5-mistral-7b",                 #"mathstral-7b-v0.1",  # LM Studio ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ ì´ë¦„
            messages=messages,
            temperature=0.7,
            max_tokens=300
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print("âŒ GPT ì‘ë‹µ ì˜¤ë¥˜:", e)
        return "GPT ë‹µë³€ì„ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

# í˜ì´ì§€ë³„ ì§ˆë¬¸ Top 3 í´ëŸ¬ìŠ¤í„° ëŒ€í‘œ ì§ˆë¬¸ ì¶”ì¶œ
def get_top3_questions_by_page(page_num):
    # 1. í•´ë‹¹ í˜ì´ì§€ì˜ ì§ˆë¬¸ê³¼ ì„ë² ë”© ì¡°íšŒ
    cursor.execute("""
        SELECT q.id, q.questions, qe.embedding
        FROM questions q
        JOIN question_embeddings qe ON q.id = qe.question_id
        WHERE q.page_num = %s
    """, (page_num,))
    rows = cursor.fetchall()

    if not rows:
        return []
    
    # ì§ˆë¬¸ì´ 1ê°œë¿ì´ë©´ ê·¸ëƒ¥ ë°˜í™˜
    if len(rows) == 1:
        return [{"question": rows[0]['questions'], "count": 1}]

    embeddings = [json.loads(row['embedding']) for row in rows]
    questions = [row['questions'] for row in rows]

    # 2D ë°°ì—´ë¡œ ë³€í™˜ (ì§ˆë¬¸ì´ 1ê°œì—¬ë„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
    embeddings = np.array(embeddings).reshape(-1, len(embeddings[0]))

    # 2. í´ëŸ¬ìŠ¤í„°ë§ (1ê°œë§Œ ìˆì–´ë„ í´ëŸ¬ìŠ¤í„° ì¸ì •)
    clustering = DBSCAN(eps=0.4, min_samples=1, metric='cosine').fit(embeddings)
    labels = clustering.labels_

    # 3. í´ëŸ¬ìŠ¤í„°ë³„ ëŒ€í‘œ ì§ˆë¬¸ ì¶”ì¶œ
    cluster_map = defaultdict(list)
    for label, q in zip(labels, questions):
        if label != -1:
            cluster_map[label].append(q)

    cluster_counts = sorted(cluster_map.items(), key=lambda x: len(x[1]), reverse=True)
    top_questions = []

    # ëŒ€í‘œ ì§ˆë¬¸ ì¶”ì¶œ
    for _, qs in cluster_counts[:3]:
        representative = Counter(qs).most_common(1)[0][0]
        top_questions.append({"question": representative, "count": len(qs)})

    # 4. í´ëŸ¬ìŠ¤í„°ê°€ 3ê°œ ë¯¸ë§Œì´ë©´, ë‚˜ë¨¸ì§€ëŠ” ì„ì˜ ì§ˆë¬¸ìœ¼ë¡œ ì±„ìš°ê¸°
    if len(top_questions) < 3:
        remaining = 3 - len(top_questions)
        used_questions = set(q['question'] for q in top_questions)
        remaining_pool = [q for q in questions if q not in used_questions]
        random.shuffle(remaining_pool)
        for q in remaining_pool[:remaining]:
            top_questions.append({"question": q, "count": 1})

    return top_questions


# ì§ˆë¬¸ API
@app.route('/ask', methods=['POST'])
def ask():
    try:
        data = request.get_json()
        question = data.get("question")
        slide_index = data.get("slide_index")

        if not question:
            return jsonify({"error": "ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."}), 400

        if not question:
            return jsonify({"error": "ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."}), 400

        # 1. ì§ˆë¬¸ ì„ë² ë”©
        q_embedding = model.encode(question).tolist()

        # 2. ìœ ì‚¬ ì§ˆë¬¸ í™•ì¸
        similar_id = find_similar_question(q_embedding)
        if similar_id:
            answer = get_answer_by_question_id(similar_id)
            qid = save_question(question, slide_index)
            if qid:
                save_question_embedding(qid, q_embedding)
                save_answer(qid, answer)
            return jsonify({"question": question, "answer": answer})

        # 3. ê´€ë ¨ ë¬¸ë‹¨ ì¶”ì¶œ
        context_chunks = find_relevant_story_chunks(q_embedding)

        # 4. GPTë¡œ ë‹µë³€ ìƒì„±
        answer = get_gpt_answer_with_context(question, context_chunks)

        # 5. ì €ì¥
        qid = save_question(question, slide_index)
        if qid:
            save_question_embedding(qid, q_embedding)
            save_answer(qid, answer)

        return jsonify({"question": question, "answer": answer})

    except Exception as e:
        print("âŒ /ask ì²˜ë¦¬ ì˜¤ë¥˜:", e)
        return jsonify({"error": "ì„œë²„ ì˜¤ë¥˜ ë°œìƒ"}), 500

@app.route("/story", methods=["GET"])
def index():
    return render_template("ButterflyDream.html")

@app.route("/")
def home():
    return "<h2>Hello! Go to <a href='/story'>/story</a></h2>"

@app.route("/tts", methods=["POST"])
def tts():
    try:
        data = request.get_json()
        text = data.get("text")
        print("ğŸ“© í´ë¼ì´ì–¸íŠ¸ì—ì„œ ë°›ì€ TTS í…ìŠ¤íŠ¸:", text)  # âœ… ì¶”ê°€

        if not text:
            return jsonify({"error": "í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400

        tts = gTTS(text, lang='ko')
        mp3_fp = BytesIO()
        tts.write_to_fp(mp3_fp)
        mp3_fp.seek(0)

        return send_file(mp3_fp, mimetype="audio/mpeg")

    except Exception as e:
        print("âŒ /tts ì²˜ë¦¬ ì˜¤ë¥˜:", e)
        return jsonify({"error": "TTS ì˜¤ë¥˜ ë°œìƒ"}), 500

@app.route("/top3_questions", methods=["GET"])
def top3_questions():
    page_num = request.args.get("page", type=int)
    if page_num is None:
        return jsonify({"error": "page ë²ˆí˜¸ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

    top_questions = get_top3_questions_by_page(page_num)
    return jsonify(top_questions)


if __name__ == '__main__':
    app.run(debug=True)